{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversing a Sequence\n",
    "\n",
    "\n",
    "I can't get my Transformer to work! Let's make the problem even simpler.\n",
    "\n",
    "Given a sequence of numbers, simply reverse the sequence.\n",
    "\n",
    "```\n",
    "input = 0 1 5 9 0 3 5 2 5\n",
    "reversed = 5 2 5 3 0 9 5 1 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "from radam import RAdam\n",
    "from utils import get_accuracy, get_output_for_example, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_examples: int, seq_len: int, vocab_size: int):\n",
    "    inputs = np.random.randint(0, vocab_size, size=(num_examples, seq_len))\n",
    "    outputs = np.ascontiguousarray(np.flip(inputs, 1)) #PyTorch can't handle negative strides\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8, 9, 7, 4, 1, 7, 1, 6, 9, 9]]),\n",
       " array([[9, 9, 6, 1, 7, 1, 4, 7, 9, 8]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data(num_examples=1, seq_len=10, vocab_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, num_examples, sequence_length, vocab_size):\n",
    "        self.items, self.labels = generate_data(num_examples, sequence_length, vocab_size)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = torch.Tensor(self.items[idx]).long()\n",
    "        y = torch.Tensor(self.labels[idx]).long()\n",
    "        return x.cuda(), y.cuda()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 5\n",
    "VOCAB_SIZE = 10\n",
    "\n",
    "TRN_EXAMPLES = 128\n",
    "VAL_EXAMPLES = 12\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(num_examples=TRN_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "valid_ds = ToyDataset(num_examples=VAL_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around a BERT model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Untrained BERT Model\n",
    "        config = BertConfig(vocab_size_or_config_json_file=vocab_size)\n",
    "        self.bert_model = BertModel(config)\n",
    "        self.linear = torch.nn.Linear(in_features=768, out_features=vocab_size)\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        out, _ = self.bert_model(x)\n",
    "        out = self.linear(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel(VOCAB_SIZE)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use RAdam to avoid having to use warmup\n",
    "# If we use regular Adam, this usually won't converge for long sequences\n",
    "optimizer = RAdam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 \tStep:\t 0 \tLoss:\t 2.3936386108398438\n",
      "Epoch:\t 0 \t\t\tValid Accuracy\t 0.134375\n",
      "Epoch:\t 1 \tStep:\t 0 \tLoss:\t 2.263537883758545\n",
      "Epoch:\t 1 \t\t\tValid Accuracy\t 0.275\n",
      "Epoch:\t 2 \tStep:\t 0 \tLoss:\t 2.0607337951660156\n",
      "Epoch:\t 2 \t\t\tValid Accuracy\t 0.35625\n",
      "Epoch:\t 3 \tStep:\t 0 \tLoss:\t 1.768286943435669\n",
      "Epoch:\t 3 \t\t\tValid Accuracy\t 0.4015625\n",
      "Epoch:\t 4 \tStep:\t 0 \tLoss:\t 1.6182388067245483\n",
      "Epoch:\t 4 \t\t\tValid Accuracy\t 0.446875\n",
      "Epoch:\t 5 \tStep:\t 0 \tLoss:\t 1.4450860023498535\n",
      "Epoch:\t 5 \t\t\tValid Accuracy\t 0.5109375\n",
      "Epoch:\t 6 \tStep:\t 0 \tLoss:\t 1.3252371549606323\n",
      "Epoch:\t 6 \t\t\tValid Accuracy\t 0.56406254\n",
      "Epoch:\t 7 \tStep:\t 0 \tLoss:\t 1.2489956617355347\n",
      "Epoch:\t 7 \t\t\tValid Accuracy\t 0.61875004\n",
      "Epoch:\t 8 \tStep:\t 0 \tLoss:\t 1.090881109237671\n",
      "Epoch:\t 8 \t\t\tValid Accuracy\t 0.675\n",
      "Epoch:\t 9 \tStep:\t 0 \tLoss:\t 1.0152145624160767\n",
      "Epoch:\t 9 \t\t\tValid Accuracy\t 0.72187495\n",
      "Epoch:\t 10 \tStep:\t 0 \tLoss:\t 0.8539468050003052\n",
      "Epoch:\t 10 \t\t\tValid Accuracy\t 0.803125\n",
      "Epoch:\t 11 \tStep:\t 0 \tLoss:\t 0.752048671245575\n",
      "Epoch:\t 11 \t\t\tValid Accuracy\t 0.8828125\n",
      "Epoch:\t 12 \tStep:\t 0 \tLoss:\t 0.5403026342391968\n",
      "Epoch:\t 12 \t\t\tValid Accuracy\t 0.9546875\n",
      "Epoch:\t 13 \tStep:\t 0 \tLoss:\t 0.3236461281776428\n",
      "Epoch:\t 13 \t\t\tValid Accuracy\t 0.996875\n",
      "Epoch:\t 14 \tStep:\t 0 \tLoss:\t 0.19537118077278137\n",
      "Epoch:\t 14 \t\t\tValid Accuracy\t 0.9984375\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, valid_dl, loss_fn, optimizer, num_epochs=15, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\t tensor([2, 2, 4, 6, 4], device='cuda:0')\n",
      "y:\t tensor([4, 6, 4, 2, 2], device='cuda:0')\n",
      "y_hat:\t tensor([4, 6, 4, 2, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# An example from the training set\n",
    "x, y = train_ds[0]\n",
    "y_hat = get_output_for_example(model, x)\n",
    "\n",
    "print(\"X:\\t\", x)\n",
    "print(\"y:\\t\", y)\n",
    "print(\"y_hat:\\t\", y_hat.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\t tensor([0, 1, 2, 3, 4], device='cuda:0')\n",
      "y:\t tensor([4, 3, 2, 1, 0], device='cuda:0')\n",
      "y_hat:\t tensor([4, 3, 2, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# An out-of-sample example\n",
    "x = torch.from_numpy(np.arange(SEQ_LENGTH)).long().cuda()\n",
    "y = torch.flip(x, dims=(0,))\n",
    "y_hat = get_output_for_example(model, x)\n",
    "\n",
    "print(\"X:\\t\", x)\n",
    "print(\"y:\\t\", y)\n",
    "print(\"y_hat:\\t\", y_hat.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got something simple working, let's try with longer sequences.\n",
    "\n",
    "Note that we're going to hold `TRN_EXAMPLES` fixed for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longer sequence\n",
    "SEQ_LENGTH = 100\n",
    "# The rest should be the same as above\n",
    "VOCAB_SIZE = 10\n",
    "TRN_EXAMPLES = 128\n",
    "VAL_EXAMPLES = 12\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(num_examples=TRN_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "valid_ds = ToyDataset(num_examples=VAL_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel(VOCAB_SIZE)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use RAdam to avoid having to use warmup\n",
    "# If we use regular Adam, this usually won't converge for long sequences\n",
    "optimizer = RAdam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 \tStep:\t 0 \tLoss:\t 2.484060764312744\n",
      "Epoch:\t 0 \t\t\tValid Accuracy\t 0.10148437\n",
      "Epoch:\t 1 \tStep:\t 0 \tLoss:\t 2.3821005821228027\n",
      "Epoch:\t 1 \t\t\tValid Accuracy\t 0.104453124\n",
      "Epoch:\t 2 \tStep:\t 0 \tLoss:\t 2.3782126903533936\n",
      "Epoch:\t 2 \t\t\tValid Accuracy\t 0.10296875\n",
      "Epoch:\t 3 \tStep:\t 0 \tLoss:\t 2.340113878250122\n",
      "Epoch:\t 3 \t\t\tValid Accuracy\t 0.113984376\n",
      "Epoch:\t 4 \tStep:\t 0 \tLoss:\t 2.3262312412261963\n",
      "Epoch:\t 4 \t\t\tValid Accuracy\t 0.12\n",
      "Epoch:\t 5 \tStep:\t 0 \tLoss:\t 2.3109114170074463\n",
      "Epoch:\t 5 \t\t\tValid Accuracy\t 0.12671874\n",
      "Epoch:\t 6 \tStep:\t 0 \tLoss:\t 2.300466775894165\n",
      "Epoch:\t 6 \t\t\tValid Accuracy\t 0.13382813\n",
      "Epoch:\t 7 \tStep:\t 0 \tLoss:\t 2.2993288040161133\n",
      "Epoch:\t 7 \t\t\tValid Accuracy\t 0.1359375\n",
      "Epoch:\t 8 \tStep:\t 0 \tLoss:\t 2.2852816581726074\n",
      "Epoch:\t 8 \t\t\tValid Accuracy\t 0.1425\n",
      "Epoch:\t 9 \tStep:\t 0 \tLoss:\t 2.2793452739715576\n",
      "Epoch:\t 9 \t\t\tValid Accuracy\t 0.15539062\n",
      "Epoch:\t 10 \tStep:\t 0 \tLoss:\t 2.2700774669647217\n",
      "Epoch:\t 10 \t\t\tValid Accuracy\t 0.15609375\n",
      "Epoch:\t 11 \tStep:\t 0 \tLoss:\t 2.2544608116149902\n",
      "Epoch:\t 11 \t\t\tValid Accuracy\t 0.1659375\n",
      "Epoch:\t 12 \tStep:\t 0 \tLoss:\t 2.2489430904388428\n",
      "Epoch:\t 12 \t\t\tValid Accuracy\t 0.1759375\n",
      "Epoch:\t 13 \tStep:\t 0 \tLoss:\t 2.2465364933013916\n",
      "Epoch:\t 13 \t\t\tValid Accuracy\t 0.1821875\n",
      "Epoch:\t 14 \tStep:\t 0 \tLoss:\t 2.2281668186187744\n",
      "Epoch:\t 14 \t\t\tValid Accuracy\t 0.18875\n",
      "Epoch:\t 15 \tStep:\t 0 \tLoss:\t 2.2175087928771973\n",
      "Epoch:\t 15 \t\t\tValid Accuracy\t 0.19226561\n",
      "Epoch:\t 16 \tStep:\t 0 \tLoss:\t 2.201540470123291\n",
      "Epoch:\t 16 \t\t\tValid Accuracy\t 0.19976562\n",
      "Epoch:\t 17 \tStep:\t 0 \tLoss:\t 2.1894302368164062\n",
      "Epoch:\t 17 \t\t\tValid Accuracy\t 0.20882812\n",
      "Epoch:\t 18 \tStep:\t 0 \tLoss:\t 2.1693813800811768\n",
      "Epoch:\t 18 \t\t\tValid Accuracy\t 0.21281248\n",
      "Epoch:\t 19 \tStep:\t 0 \tLoss:\t 2.1654233932495117\n",
      "Epoch:\t 19 \t\t\tValid Accuracy\t 0.22734374\n",
      "Epoch:\t 20 \tStep:\t 0 \tLoss:\t 2.140986680984497\n",
      "Epoch:\t 20 \t\t\tValid Accuracy\t 0.22992188\n",
      "Epoch:\t 21 \tStep:\t 0 \tLoss:\t 2.13132643699646\n",
      "Epoch:\t 21 \t\t\tValid Accuracy\t 0.23749998\n",
      "Epoch:\t 22 \tStep:\t 0 \tLoss:\t 2.118638515472412\n",
      "Epoch:\t 22 \t\t\tValid Accuracy\t 0.24171874\n",
      "Epoch:\t 23 \tStep:\t 0 \tLoss:\t 2.1043808460235596\n",
      "Epoch:\t 23 \t\t\tValid Accuracy\t 0.25148436\n",
      "Epoch:\t 24 \tStep:\t 0 \tLoss:\t 2.0936429500579834\n",
      "Epoch:\t 24 \t\t\tValid Accuracy\t 0.25640625\n",
      "Epoch:\t 25 \tStep:\t 0 \tLoss:\t 2.0730695724487305\n",
      "Epoch:\t 25 \t\t\tValid Accuracy\t 0.25742185\n",
      "Epoch:\t 26 \tStep:\t 0 \tLoss:\t 2.047445297241211\n",
      "Epoch:\t 26 \t\t\tValid Accuracy\t 0.25843748\n",
      "Epoch:\t 27 \tStep:\t 0 \tLoss:\t 2.0462276935577393\n",
      "Epoch:\t 27 \t\t\tValid Accuracy\t 0.263125\n",
      "Epoch:\t 28 \tStep:\t 0 \tLoss:\t 2.0282583236694336\n",
      "Epoch:\t 28 \t\t\tValid Accuracy\t 0.26546875\n",
      "Epoch:\t 29 \tStep:\t 0 \tLoss:\t 2.0161967277526855\n",
      "Epoch:\t 29 \t\t\tValid Accuracy\t 0.270625\n",
      "Epoch:\t 30 \tStep:\t 0 \tLoss:\t 2.010450601577759\n",
      "Epoch:\t 30 \t\t\tValid Accuracy\t 0.27429688\n",
      "Epoch:\t 31 \tStep:\t 0 \tLoss:\t 2.005872964859009\n",
      "Epoch:\t 31 \t\t\tValid Accuracy\t 0.2799219\n",
      "Epoch:\t 32 \tStep:\t 0 \tLoss:\t 1.9868792295455933\n",
      "Epoch:\t 32 \t\t\tValid Accuracy\t 0.28265625\n",
      "Epoch:\t 33 \tStep:\t 0 \tLoss:\t 1.9886703491210938\n",
      "Epoch:\t 33 \t\t\tValid Accuracy\t 0.28929687\n",
      "Epoch:\t 34 \tStep:\t 0 \tLoss:\t 1.9788857698440552\n",
      "Epoch:\t 34 \t\t\tValid Accuracy\t 0.29507813\n",
      "Epoch:\t 35 \tStep:\t 0 \tLoss:\t 1.9560314416885376\n",
      "Epoch:\t 35 \t\t\tValid Accuracy\t 0.2944531\n",
      "Epoch:\t 36 \tStep:\t 0 \tLoss:\t 1.9595592021942139\n",
      "Epoch:\t 36 \t\t\tValid Accuracy\t 0.30148438\n",
      "Epoch:\t 37 \tStep:\t 0 \tLoss:\t 1.9254399538040161\n",
      "Epoch:\t 37 \t\t\tValid Accuracy\t 0.30632812\n",
      "Epoch:\t 38 \tStep:\t 0 \tLoss:\t 1.9208323955535889\n",
      "Epoch:\t 38 \t\t\tValid Accuracy\t 0.30773437\n",
      "Epoch:\t 39 \tStep:\t 0 \tLoss:\t 1.9008904695510864\n",
      "Epoch:\t 39 \t\t\tValid Accuracy\t 0.3146875\n",
      "Epoch:\t 40 \tStep:\t 0 \tLoss:\t 1.9108920097351074\n",
      "Epoch:\t 40 \t\t\tValid Accuracy\t 0.3191406\n",
      "Epoch:\t 41 \tStep:\t 0 \tLoss:\t 1.883895754814148\n",
      "Epoch:\t 41 \t\t\tValid Accuracy\t 0.32171875\n",
      "Epoch:\t 42 \tStep:\t 0 \tLoss:\t 1.8788745403289795\n",
      "Epoch:\t 42 \t\t\tValid Accuracy\t 0.32546872\n",
      "Epoch:\t 43 \tStep:\t 0 \tLoss:\t 1.8696725368499756\n",
      "Epoch:\t 43 \t\t\tValid Accuracy\t 0.33421874\n",
      "Epoch:\t 44 \tStep:\t 0 \tLoss:\t 1.839535117149353\n",
      "Epoch:\t 44 \t\t\tValid Accuracy\t 0.3360156\n",
      "Epoch:\t 45 \tStep:\t 0 \tLoss:\t 1.8390929698944092\n",
      "Epoch:\t 45 \t\t\tValid Accuracy\t 0.35210937\n",
      "Epoch:\t 46 \tStep:\t 0 \tLoss:\t 1.7907824516296387\n",
      "Epoch:\t 46 \t\t\tValid Accuracy\t 0.36695313\n",
      "Epoch:\t 47 \tStep:\t 0 \tLoss:\t 1.8066843748092651\n",
      "Epoch:\t 47 \t\t\tValid Accuracy\t 0.3750781\n",
      "Epoch:\t 48 \tStep:\t 0 \tLoss:\t 1.7436906099319458\n",
      "Epoch:\t 48 \t\t\tValid Accuracy\t 0.38765624\n",
      "Epoch:\t 49 \tStep:\t 0 \tLoss:\t 1.7217414379119873\n",
      "Epoch:\t 49 \t\t\tValid Accuracy\t 0.3954687\n",
      "Epoch:\t 50 \tStep:\t 0 \tLoss:\t 1.727271556854248\n",
      "Epoch:\t 50 \t\t\tValid Accuracy\t 0.40023437\n",
      "Epoch:\t 51 \tStep:\t 0 \tLoss:\t 1.6771342754364014\n",
      "Epoch:\t 51 \t\t\tValid Accuracy\t 0.42328125\n",
      "Epoch:\t 52 \tStep:\t 0 \tLoss:\t 1.6428043842315674\n",
      "Epoch:\t 52 \t\t\tValid Accuracy\t 0.4386719\n",
      "Epoch:\t 53 \tStep:\t 0 \tLoss:\t 1.597060203552246\n",
      "Epoch:\t 53 \t\t\tValid Accuracy\t 0.45687497\n",
      "Epoch:\t 54 \tStep:\t 0 \tLoss:\t 1.5465909242630005\n",
      "Epoch:\t 54 \t\t\tValid Accuracy\t 0.47695312\n",
      "Epoch:\t 55 \tStep:\t 0 \tLoss:\t 1.4759243726730347\n",
      "Epoch:\t 55 \t\t\tValid Accuracy\t 0.4988281\n",
      "Epoch:\t 56 \tStep:\t 0 \tLoss:\t 1.4512791633605957\n",
      "Epoch:\t 56 \t\t\tValid Accuracy\t 0.54164064\n",
      "Epoch:\t 57 \tStep:\t 0 \tLoss:\t 1.352484107017517\n",
      "Epoch:\t 57 \t\t\tValid Accuracy\t 0.5740625\n",
      "Epoch:\t 58 \tStep:\t 0 \tLoss:\t 1.2291516065597534\n",
      "Epoch:\t 58 \t\t\tValid Accuracy\t 0.6672656\n",
      "Epoch:\t 59 \tStep:\t 0 \tLoss:\t 1.0423766374588013\n",
      "Epoch:\t 59 \t\t\tValid Accuracy\t 0.8010156\n",
      "Epoch:\t 60 \tStep:\t 0 \tLoss:\t 0.6690913438796997\n",
      "Epoch:\t 60 \t\t\tValid Accuracy\t 0.90999997\n",
      "Epoch:\t 61 \tStep:\t 0 \tLoss:\t 0.3102421760559082\n",
      "Epoch:\t 61 \t\t\tValid Accuracy\t 0.9800781\n",
      "Epoch:\t 62 \tStep:\t 0 \tLoss:\t 0.09475748240947723\n",
      "Epoch:\t 62 \t\t\tValid Accuracy\t 0.9935156\n",
      "Epoch:\t 63 \tStep:\t 0 \tLoss:\t 0.030003895983099937\n",
      "Epoch:\t 63 \t\t\tValid Accuracy\t 0.99671876\n",
      "Epoch:\t 64 \tStep:\t 0 \tLoss:\t 0.016887450590729713\n",
      "Epoch:\t 64 \t\t\tValid Accuracy\t 0.99796873\n",
      "Epoch:\t 65 \tStep:\t 0 \tLoss:\t 0.011643038131296635\n",
      "Epoch:\t 65 \t\t\tValid Accuracy\t 0.9985937\n",
      "Epoch:\t 66 \tStep:\t 0 \tLoss:\t 0.005229762755334377\n",
      "Epoch:\t 66 \t\t\tValid Accuracy\t 0.99859375\n",
      "Epoch:\t 67 \tStep:\t 0 \tLoss:\t 0.006910675670951605\n",
      "Epoch:\t 67 \t\t\tValid Accuracy\t 0.9994531\n",
      "Epoch:\t 68 \tStep:\t 0 \tLoss:\t 0.0031009926460683346\n",
      "Epoch:\t 68 \t\t\tValid Accuracy\t 0.9991406\n",
      "Epoch:\t 69 \tStep:\t 0 \tLoss:\t 0.007144525181502104\n",
      "Epoch:\t 69 \t\t\tValid Accuracy\t 0.9995312\n",
      "Epoch:\t 70 \tStep:\t 0 \tLoss:\t 0.0018558534793555737\n",
      "Epoch:\t 70 \t\t\tValid Accuracy\t 0.99960935\n",
      "Epoch:\t 71 \tStep:\t 0 \tLoss:\t 0.00189419265370816\n",
      "Epoch:\t 71 \t\t\tValid Accuracy\t 0.9996875\n",
      "Epoch:\t 72 \tStep:\t 0 \tLoss:\t 0.0021286900155246258\n",
      "Epoch:\t 72 \t\t\tValid Accuracy\t 0.999375\n",
      "Epoch:\t 73 \tStep:\t 0 \tLoss:\t 0.0025390321388840675\n",
      "Epoch:\t 73 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 74 \tStep:\t 0 \tLoss:\t 0.002354653552174568\n",
      "Epoch:\t 74 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 75 \tStep:\t 0 \tLoss:\t 0.002011945005506277\n",
      "Epoch:\t 75 \t\t\tValid Accuracy\t 0.9996875\n",
      "Epoch:\t 76 \tStep:\t 0 \tLoss:\t 0.0021333941258490086\n",
      "Epoch:\t 76 \t\t\tValid Accuracy\t 0.9996875\n",
      "Epoch:\t 77 \tStep:\t 0 \tLoss:\t 0.0021691357251256704\n",
      "Epoch:\t 77 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 78 \tStep:\t 0 \tLoss:\t 0.0019388562068343163\n",
      "Epoch:\t 78 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 79 \tStep:\t 0 \tLoss:\t 0.001093433820642531\n",
      "Epoch:\t 79 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 80 \tStep:\t 0 \tLoss:\t 0.0013713428052142262\n",
      "Epoch:\t 80 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 81 \tStep:\t 0 \tLoss:\t 0.0014387014089152217\n",
      "Epoch:\t 81 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 82 \tStep:\t 0 \tLoss:\t 0.0016011708648875356\n",
      "Epoch:\t 82 \t\t\tValid Accuracy\t 0.99960935\n",
      "Epoch:\t 83 \tStep:\t 0 \tLoss:\t 0.0012990477262064815\n",
      "Epoch:\t 83 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 84 \tStep:\t 0 \tLoss:\t 0.0007553422474302351\n",
      "Epoch:\t 84 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 85 \tStep:\t 0 \tLoss:\t 0.0010884698713198304\n",
      "Epoch:\t 85 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 86 \tStep:\t 0 \tLoss:\t 0.0007088184356689453\n",
      "Epoch:\t 86 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 87 \tStep:\t 0 \tLoss:\t 0.0010221573757007718\n",
      "Epoch:\t 87 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 88 \tStep:\t 0 \tLoss:\t 0.0005717652966268361\n",
      "Epoch:\t 88 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 89 \tStep:\t 0 \tLoss:\t 0.000658092787489295\n",
      "Epoch:\t 89 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 90 \tStep:\t 0 \tLoss:\t 0.0010319116991013288\n",
      "Epoch:\t 90 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 91 \tStep:\t 0 \tLoss:\t 0.0009906926425173879\n",
      "Epoch:\t 91 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 92 \tStep:\t 0 \tLoss:\t 0.0005314770387485623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 92 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 93 \tStep:\t 0 \tLoss:\t 0.00048018962843343616\n",
      "Epoch:\t 93 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 94 \tStep:\t 0 \tLoss:\t 0.0004154345369897783\n",
      "Epoch:\t 94 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 95 \tStep:\t 0 \tLoss:\t 0.0005855700583197176\n",
      "Epoch:\t 95 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 96 \tStep:\t 0 \tLoss:\t 0.0010000172769650817\n",
      "Epoch:\t 96 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 97 \tStep:\t 0 \tLoss:\t 0.0003944307682104409\n",
      "Epoch:\t 97 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 98 \tStep:\t 0 \tLoss:\t 0.00048108608461916447\n",
      "Epoch:\t 98 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 99 \tStep:\t 0 \tLoss:\t 0.0005362260271795094\n",
      "Epoch:\t 99 \t\t\tValid Accuracy\t 1.0\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, valid_dl, loss_fn, optimizer, num_epochs=100, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can still learn a solution to this problem with a training set of just 128 examples, it just takes us a lot longer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing but with a larger vocab. \n",
    "\n",
    "Note that we'll hold all other parameters at their original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longer sequence\n",
    "SEQ_LENGTH = 10\n",
    "# The rest should be the same as above\n",
    "VOCAB_SIZE = 1000\n",
    "TRN_EXAMPLES = 128\n",
    "VAL_EXAMPLES = 12\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(num_examples=TRN_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "valid_ds = ToyDataset(num_examples=VAL_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel(VOCAB_SIZE)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use RAdam to avoid having to use warmup\n",
    "# If we use regular Adam, this usually won't converge for long sequences\n",
    "optimizer = RAdam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 \tStep:\t 0 \tLoss:\t 7.012752532958984\n",
      "Epoch:\t 0 \t\t\tValid Accuracy\t 0.00078125\n",
      "Epoch:\t 1 \tStep:\t 0 \tLoss:\t 6.968691349029541\n",
      "Epoch:\t 1 \t\t\tValid Accuracy\t 0.003125\n",
      "Epoch:\t 2 \tStep:\t 0 \tLoss:\t 6.857752799987793\n",
      "Epoch:\t 2 \t\t\tValid Accuracy\t 0.00625\n",
      "Epoch:\t 3 \tStep:\t 0 \tLoss:\t 6.7144598960876465\n",
      "Epoch:\t 3 \t\t\tValid Accuracy\t 0.00703125\n",
      "Epoch:\t 4 \tStep:\t 0 \tLoss:\t 6.581044673919678\n",
      "Epoch:\t 4 \t\t\tValid Accuracy\t 0.0171875\n",
      "Epoch:\t 5 \tStep:\t 0 \tLoss:\t 6.428334712982178\n",
      "Epoch:\t 5 \t\t\tValid Accuracy\t 0.03671875\n",
      "Epoch:\t 6 \tStep:\t 0 \tLoss:\t 6.266859531402588\n",
      "Epoch:\t 6 \t\t\tValid Accuracy\t 0.08359375\n",
      "Epoch:\t 7 \tStep:\t 0 \tLoss:\t 6.009130001068115\n",
      "Epoch:\t 7 \t\t\tValid Accuracy\t 0.1359375\n",
      "Epoch:\t 8 \tStep:\t 0 \tLoss:\t 5.766554832458496\n",
      "Epoch:\t 8 \t\t\tValid Accuracy\t 0.215625\n",
      "Epoch:\t 9 \tStep:\t 0 \tLoss:\t 5.511596202850342\n",
      "Epoch:\t 9 \t\t\tValid Accuracy\t 0.33359376\n",
      "Epoch:\t 10 \tStep:\t 0 \tLoss:\t 5.242946624755859\n",
      "Epoch:\t 10 \t\t\tValid Accuracy\t 0.5023438\n",
      "Epoch:\t 11 \tStep:\t 0 \tLoss:\t 4.986907005310059\n",
      "Epoch:\t 11 \t\t\tValid Accuracy\t 0.63984376\n",
      "Epoch:\t 12 \tStep:\t 0 \tLoss:\t 4.638279914855957\n",
      "Epoch:\t 12 \t\t\tValid Accuracy\t 0.79218745\n",
      "Epoch:\t 13 \tStep:\t 0 \tLoss:\t 4.344457149505615\n",
      "Epoch:\t 13 \t\t\tValid Accuracy\t 0.87968755\n",
      "Epoch:\t 14 \tStep:\t 0 \tLoss:\t 4.044671058654785\n",
      "Epoch:\t 14 \t\t\tValid Accuracy\t 0.9296875\n",
      "Epoch:\t 15 \tStep:\t 0 \tLoss:\t 3.714698314666748\n",
      "Epoch:\t 15 \t\t\tValid Accuracy\t 0.959375\n",
      "Epoch:\t 16 \tStep:\t 0 \tLoss:\t 3.4517345428466797\n",
      "Epoch:\t 16 \t\t\tValid Accuracy\t 0.975\n",
      "Epoch:\t 17 \tStep:\t 0 \tLoss:\t 3.226247787475586\n",
      "Epoch:\t 17 \t\t\tValid Accuracy\t 0.9820312\n",
      "Epoch:\t 18 \tStep:\t 0 \tLoss:\t 2.905740261077881\n",
      "Epoch:\t 18 \t\t\tValid Accuracy\t 0.9851563\n",
      "Epoch:\t 19 \tStep:\t 0 \tLoss:\t 2.6423215866088867\n",
      "Epoch:\t 19 \t\t\tValid Accuracy\t 0.98828125\n",
      "Epoch:\t 20 \tStep:\t 0 \tLoss:\t 2.3972554206848145\n",
      "Epoch:\t 20 \t\t\tValid Accuracy\t 0.99375\n",
      "Epoch:\t 21 \tStep:\t 0 \tLoss:\t 2.165250301361084\n",
      "Epoch:\t 21 \t\t\tValid Accuracy\t 0.99375004\n",
      "Epoch:\t 22 \tStep:\t 0 \tLoss:\t 1.9252420663833618\n",
      "Epoch:\t 22 \t\t\tValid Accuracy\t 0.99375004\n",
      "Epoch:\t 23 \tStep:\t 0 \tLoss:\t 1.7140576839447021\n",
      "Epoch:\t 23 \t\t\tValid Accuracy\t 0.9976562\n",
      "Epoch:\t 24 \tStep:\t 0 \tLoss:\t 1.5993595123291016\n",
      "Epoch:\t 24 \t\t\tValid Accuracy\t 0.9984375\n",
      "Epoch:\t 25 \tStep:\t 0 \tLoss:\t 1.4115701913833618\n",
      "Epoch:\t 25 \t\t\tValid Accuracy\t 0.99921876\n",
      "Epoch:\t 26 \tStep:\t 0 \tLoss:\t 1.2180982828140259\n",
      "Epoch:\t 26 \t\t\tValid Accuracy\t 0.9984375\n",
      "Epoch:\t 27 \tStep:\t 0 \tLoss:\t 1.0705112218856812\n",
      "Epoch:\t 27 \t\t\tValid Accuracy\t 0.99921876\n",
      "Epoch:\t 28 \tStep:\t 0 \tLoss:\t 0.9936461448669434\n",
      "Epoch:\t 28 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 29 \tStep:\t 0 \tLoss:\t 0.8596099615097046\n",
      "Epoch:\t 29 \t\t\tValid Accuracy\t 0.9984375\n",
      "Epoch:\t 30 \tStep:\t 0 \tLoss:\t 0.7405803799629211\n",
      "Epoch:\t 30 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 31 \tStep:\t 0 \tLoss:\t 0.6688705086708069\n",
      "Epoch:\t 31 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 32 \tStep:\t 0 \tLoss:\t 0.5992082953453064\n",
      "Epoch:\t 32 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 33 \tStep:\t 0 \tLoss:\t 0.5344821214675903\n",
      "Epoch:\t 33 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 34 \tStep:\t 0 \tLoss:\t 0.490858793258667\n",
      "Epoch:\t 34 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 35 \tStep:\t 0 \tLoss:\t 0.4385548233985901\n",
      "Epoch:\t 35 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 36 \tStep:\t 0 \tLoss:\t 0.39347144961357117\n",
      "Epoch:\t 36 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 37 \tStep:\t 0 \tLoss:\t 0.35113245248794556\n",
      "Epoch:\t 37 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 38 \tStep:\t 0 \tLoss:\t 0.32418978214263916\n",
      "Epoch:\t 38 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 39 \tStep:\t 0 \tLoss:\t 0.30566340684890747\n",
      "Epoch:\t 39 \t\t\tValid Accuracy\t 1.0\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, valid_dl, loss_fn, optimizer, num_epochs=40, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also learn a solution to this problem in roughly 30-50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Vocab and Longer Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it about as hard as we can. \n",
    "\n",
    "We'll crank up both the vocabular and sequence length while keeping everything else the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longer sequence and larger vocabular\n",
    "SEQ_LENGTH = 100\n",
    "VOCAB_SIZE = 1000\n",
    "# The rest should be the same as above\n",
    "TRN_EXAMPLES = 128\n",
    "VAL_EXAMPLES = 12\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(num_examples=TRN_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "valid_ds = ToyDataset(num_examples=VAL_EXAMPLES, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel(VOCAB_SIZE)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We use RAdam to avoid having to use warmup\n",
    "# If we use regular Adam, this usually won't converge for long sequences\n",
    "optimizer = RAdam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0 \tStep:\t 0 \tLoss:\t 7.081050395965576\n",
      "Epoch:\t 0 \t\t\tValid Accuracy\t 0.00078124995\n",
      "Epoch:\t 1 \tStep:\t 0 \tLoss:\t 7.065215587615967\n",
      "Epoch:\t 1 \t\t\tValid Accuracy\t 0.00070312497\n",
      "Epoch:\t 2 \tStep:\t 0 \tLoss:\t 7.002694606781006\n",
      "Epoch:\t 2 \t\t\tValid Accuracy\t 0.0015624999\n",
      "Epoch:\t 3 \tStep:\t 0 \tLoss:\t 6.952529430389404\n",
      "Epoch:\t 3 \t\t\tValid Accuracy\t 0.00140625\n",
      "Epoch:\t 4 \tStep:\t 0 \tLoss:\t 6.907620906829834\n",
      "Epoch:\t 4 \t\t\tValid Accuracy\t 0.002421875\n",
      "Epoch:\t 5 \tStep:\t 0 \tLoss:\t 6.8764729499816895\n",
      "Epoch:\t 5 \t\t\tValid Accuracy\t 0.0027343747\n",
      "Epoch:\t 6 \tStep:\t 0 \tLoss:\t 6.852637767791748\n",
      "Epoch:\t 6 \t\t\tValid Accuracy\t 0.00375\n",
      "Epoch:\t 7 \tStep:\t 0 \tLoss:\t 6.813115119934082\n",
      "Epoch:\t 7 \t\t\tValid Accuracy\t 0.0052343747\n",
      "Epoch:\t 8 \tStep:\t 0 \tLoss:\t 6.747159481048584\n",
      "Epoch:\t 8 \t\t\tValid Accuracy\t 0.009921875\n",
      "Epoch:\t 9 \tStep:\t 0 \tLoss:\t 6.6566009521484375\n",
      "Epoch:\t 9 \t\t\tValid Accuracy\t 0.013828125\n",
      "Epoch:\t 10 \tStep:\t 0 \tLoss:\t 6.5482306480407715\n",
      "Epoch:\t 10 \t\t\tValid Accuracy\t 0.021015625\n",
      "Epoch:\t 11 \tStep:\t 0 \tLoss:\t 6.436605453491211\n",
      "Epoch:\t 11 \t\t\tValid Accuracy\t 0.031171877\n",
      "Epoch:\t 12 \tStep:\t 0 \tLoss:\t 6.302584171295166\n",
      "Epoch:\t 12 \t\t\tValid Accuracy\t 0.049921874\n",
      "Epoch:\t 13 \tStep:\t 0 \tLoss:\t 6.176082611083984\n",
      "Epoch:\t 13 \t\t\tValid Accuracy\t 0.06546874\n",
      "Epoch:\t 14 \tStep:\t 0 \tLoss:\t 6.067416191101074\n",
      "Epoch:\t 14 \t\t\tValid Accuracy\t 0.088281244\n",
      "Epoch:\t 15 \tStep:\t 0 \tLoss:\t 5.9485344886779785\n",
      "Epoch:\t 15 \t\t\tValid Accuracy\t 0.11101562\n",
      "Epoch:\t 16 \tStep:\t 0 \tLoss:\t 5.824863433837891\n",
      "Epoch:\t 16 \t\t\tValid Accuracy\t 0.14375\n",
      "Epoch:\t 17 \tStep:\t 0 \tLoss:\t 5.702966690063477\n",
      "Epoch:\t 17 \t\t\tValid Accuracy\t 0.168125\n",
      "Epoch:\t 18 \tStep:\t 0 \tLoss:\t 5.58085823059082\n",
      "Epoch:\t 18 \t\t\tValid Accuracy\t 0.20640624\n",
      "Epoch:\t 19 \tStep:\t 0 \tLoss:\t 5.474221229553223\n",
      "Epoch:\t 19 \t\t\tValid Accuracy\t 0.24179688\n",
      "Epoch:\t 20 \tStep:\t 0 \tLoss:\t 5.364839553833008\n",
      "Epoch:\t 20 \t\t\tValid Accuracy\t 0.28140622\n",
      "Epoch:\t 21 \tStep:\t 0 \tLoss:\t 5.258869171142578\n",
      "Epoch:\t 21 \t\t\tValid Accuracy\t 0.32023436\n",
      "Epoch:\t 22 \tStep:\t 0 \tLoss:\t 5.153636455535889\n",
      "Epoch:\t 22 \t\t\tValid Accuracy\t 0.35835937\n",
      "Epoch:\t 23 \tStep:\t 0 \tLoss:\t 5.0400776863098145\n",
      "Epoch:\t 23 \t\t\tValid Accuracy\t 0.40210935\n",
      "Epoch:\t 24 \tStep:\t 0 \tLoss:\t 4.943546295166016\n",
      "Epoch:\t 24 \t\t\tValid Accuracy\t 0.44117188\n",
      "Epoch:\t 25 \tStep:\t 0 \tLoss:\t 4.823176860809326\n",
      "Epoch:\t 25 \t\t\tValid Accuracy\t 0.47648436\n",
      "Epoch:\t 26 \tStep:\t 0 \tLoss:\t 4.716954231262207\n",
      "Epoch:\t 26 \t\t\tValid Accuracy\t 0.50812495\n",
      "Epoch:\t 27 \tStep:\t 0 \tLoss:\t 4.6050190925598145\n",
      "Epoch:\t 27 \t\t\tValid Accuracy\t 0.54507816\n",
      "Epoch:\t 28 \tStep:\t 0 \tLoss:\t 4.512078285217285\n",
      "Epoch:\t 28 \t\t\tValid Accuracy\t 0.57789063\n",
      "Epoch:\t 29 \tStep:\t 0 \tLoss:\t 4.391274929046631\n",
      "Epoch:\t 29 \t\t\tValid Accuracy\t 0.60648435\n",
      "Epoch:\t 30 \tStep:\t 0 \tLoss:\t 4.285567760467529\n",
      "Epoch:\t 30 \t\t\tValid Accuracy\t 0.6354687\n",
      "Epoch:\t 31 \tStep:\t 0 \tLoss:\t 4.179307460784912\n",
      "Epoch:\t 31 \t\t\tValid Accuracy\t 0.66359377\n",
      "Epoch:\t 32 \tStep:\t 0 \tLoss:\t 4.0951385498046875\n",
      "Epoch:\t 32 \t\t\tValid Accuracy\t 0.68562496\n",
      "Epoch:\t 33 \tStep:\t 0 \tLoss:\t 3.969197988510132\n",
      "Epoch:\t 33 \t\t\tValid Accuracy\t 0.713125\n",
      "Epoch:\t 34 \tStep:\t 0 \tLoss:\t 3.861886978149414\n",
      "Epoch:\t 34 \t\t\tValid Accuracy\t 0.73828125\n",
      "Epoch:\t 35 \tStep:\t 0 \tLoss:\t 3.7450923919677734\n",
      "Epoch:\t 35 \t\t\tValid Accuracy\t 0.7604687\n",
      "Epoch:\t 36 \tStep:\t 0 \tLoss:\t 3.63710880279541\n",
      "Epoch:\t 36 \t\t\tValid Accuracy\t 0.78\n",
      "Epoch:\t 37 \tStep:\t 0 \tLoss:\t 3.5426993370056152\n",
      "Epoch:\t 37 \t\t\tValid Accuracy\t 0.79625\n",
      "Epoch:\t 38 \tStep:\t 0 \tLoss:\t 3.41827392578125\n",
      "Epoch:\t 38 \t\t\tValid Accuracy\t 0.81937504\n",
      "Epoch:\t 39 \tStep:\t 0 \tLoss:\t 3.3232483863830566\n",
      "Epoch:\t 39 \t\t\tValid Accuracy\t 0.8371093\n",
      "Epoch:\t 40 \tStep:\t 0 \tLoss:\t 3.2399587631225586\n",
      "Epoch:\t 40 \t\t\tValid Accuracy\t 0.8522656\n",
      "Epoch:\t 41 \tStep:\t 0 \tLoss:\t 3.0973217487335205\n",
      "Epoch:\t 41 \t\t\tValid Accuracy\t 0.8655468\n",
      "Epoch:\t 42 \tStep:\t 0 \tLoss:\t 3.011444091796875\n",
      "Epoch:\t 42 \t\t\tValid Accuracy\t 0.8861718\n",
      "Epoch:\t 43 \tStep:\t 0 \tLoss:\t 2.8936312198638916\n",
      "Epoch:\t 43 \t\t\tValid Accuracy\t 0.8954687\n",
      "Epoch:\t 44 \tStep:\t 0 \tLoss:\t 2.780806541442871\n",
      "Epoch:\t 44 \t\t\tValid Accuracy\t 0.90968746\n",
      "Epoch:\t 45 \tStep:\t 0 \tLoss:\t 2.6743898391723633\n",
      "Epoch:\t 45 \t\t\tValid Accuracy\t 0.92156243\n",
      "Epoch:\t 46 \tStep:\t 0 \tLoss:\t 2.5813653469085693\n",
      "Epoch:\t 46 \t\t\tValid Accuracy\t 0.92812496\n",
      "Epoch:\t 47 \tStep:\t 0 \tLoss:\t 2.4577600955963135\n",
      "Epoch:\t 47 \t\t\tValid Accuracy\t 0.9383593\n",
      "Epoch:\t 48 \tStep:\t 0 \tLoss:\t 2.3482589721679688\n",
      "Epoch:\t 48 \t\t\tValid Accuracy\t 0.9429687\n",
      "Epoch:\t 49 \tStep:\t 0 \tLoss:\t 2.2629284858703613\n",
      "Epoch:\t 49 \t\t\tValid Accuracy\t 0.9489843\n",
      "Epoch:\t 50 \tStep:\t 0 \tLoss:\t 2.147059202194214\n",
      "Epoch:\t 50 \t\t\tValid Accuracy\t 0.951875\n",
      "Epoch:\t 51 \tStep:\t 0 \tLoss:\t 2.034393310546875\n",
      "Epoch:\t 51 \t\t\tValid Accuracy\t 0.9617969\n",
      "Epoch:\t 52 \tStep:\t 0 \tLoss:\t 1.9315944910049438\n",
      "Epoch:\t 52 \t\t\tValid Accuracy\t 0.96554685\n",
      "Epoch:\t 53 \tStep:\t 0 \tLoss:\t 1.8157402276992798\n",
      "Epoch:\t 53 \t\t\tValid Accuracy\t 0.9685156\n",
      "Epoch:\t 54 \tStep:\t 0 \tLoss:\t 1.735387921333313\n",
      "Epoch:\t 54 \t\t\tValid Accuracy\t 0.9699218\n",
      "Epoch:\t 55 \tStep:\t 0 \tLoss:\t 1.629035234451294\n",
      "Epoch:\t 55 \t\t\tValid Accuracy\t 0.97117186\n",
      "Epoch:\t 56 \tStep:\t 0 \tLoss:\t 1.5211023092269897\n",
      "Epoch:\t 56 \t\t\tValid Accuracy\t 0.97453123\n",
      "Epoch:\t 57 \tStep:\t 0 \tLoss:\t 1.4288018941879272\n",
      "Epoch:\t 57 \t\t\tValid Accuracy\t 0.97515625\n",
      "Epoch:\t 58 \tStep:\t 0 \tLoss:\t 1.343336820602417\n",
      "Epoch:\t 58 \t\t\tValid Accuracy\t 0.97875\n",
      "Epoch:\t 59 \tStep:\t 0 \tLoss:\t 1.2578394412994385\n",
      "Epoch:\t 59 \t\t\tValid Accuracy\t 0.97679687\n",
      "Epoch:\t 60 \tStep:\t 0 \tLoss:\t 1.1767958402633667\n",
      "Epoch:\t 60 \t\t\tValid Accuracy\t 0.9807031\n",
      "Epoch:\t 61 \tStep:\t 0 \tLoss:\t 1.1039804220199585\n",
      "Epoch:\t 61 \t\t\tValid Accuracy\t 0.9823437\n",
      "Epoch:\t 62 \tStep:\t 0 \tLoss:\t 1.0253673791885376\n",
      "Epoch:\t 62 \t\t\tValid Accuracy\t 0.98375\n",
      "Epoch:\t 63 \tStep:\t 0 \tLoss:\t 0.9486135244369507\n",
      "Epoch:\t 63 \t\t\tValid Accuracy\t 0.9844531\n",
      "Epoch:\t 64 \tStep:\t 0 \tLoss:\t 0.8796660900115967\n",
      "Epoch:\t 64 \t\t\tValid Accuracy\t 0.984375\n",
      "Epoch:\t 65 \tStep:\t 0 \tLoss:\t 0.8141534924507141\n",
      "Epoch:\t 65 \t\t\tValid Accuracy\t 0.9882031\n",
      "Epoch:\t 66 \tStep:\t 0 \tLoss:\t 0.7651501297950745\n",
      "Epoch:\t 66 \t\t\tValid Accuracy\t 0.9874219\n",
      "Epoch:\t 67 \tStep:\t 0 \tLoss:\t 0.7009435892105103\n",
      "Epoch:\t 67 \t\t\tValid Accuracy\t 0.98929685\n",
      "Epoch:\t 68 \tStep:\t 0 \tLoss:\t 0.6541816592216492\n",
      "Epoch:\t 68 \t\t\tValid Accuracy\t 0.99015623\n",
      "Epoch:\t 69 \tStep:\t 0 \tLoss:\t 0.6067314743995667\n",
      "Epoch:\t 69 \t\t\tValid Accuracy\t 0.99125\n",
      "Epoch:\t 70 \tStep:\t 0 \tLoss:\t 0.560376763343811\n",
      "Epoch:\t 70 \t\t\tValid Accuracy\t 0.9914844\n",
      "Epoch:\t 71 \tStep:\t 0 \tLoss:\t 0.5198121070861816\n",
      "Epoch:\t 71 \t\t\tValid Accuracy\t 0.9928906\n",
      "Epoch:\t 72 \tStep:\t 0 \tLoss:\t 0.48601922392845154\n",
      "Epoch:\t 72 \t\t\tValid Accuracy\t 0.9932031\n",
      "Epoch:\t 73 \tStep:\t 0 \tLoss:\t 0.45121434330940247\n",
      "Epoch:\t 73 \t\t\tValid Accuracy\t 0.9936719\n",
      "Epoch:\t 74 \tStep:\t 0 \tLoss:\t 0.4191676378250122\n",
      "Epoch:\t 74 \t\t\tValid Accuracy\t 0.9948437\n",
      "Epoch:\t 75 \tStep:\t 0 \tLoss:\t 0.390159010887146\n",
      "Epoch:\t 75 \t\t\tValid Accuracy\t 0.9948437\n",
      "Epoch:\t 76 \tStep:\t 0 \tLoss:\t 0.3676435947418213\n",
      "Epoch:\t 76 \t\t\tValid Accuracy\t 0.99429685\n",
      "Epoch:\t 77 \tStep:\t 0 \tLoss:\t 0.34115973114967346\n",
      "Epoch:\t 77 \t\t\tValid Accuracy\t 0.9950781\n",
      "Epoch:\t 78 \tStep:\t 0 \tLoss:\t 0.3232889473438263\n",
      "Epoch:\t 78 \t\t\tValid Accuracy\t 0.99664056\n",
      "Epoch:\t 79 \tStep:\t 0 \tLoss:\t 0.29428336024284363\n",
      "Epoch:\t 79 \t\t\tValid Accuracy\t 0.9960937\n",
      "Epoch:\t 80 \tStep:\t 0 \tLoss:\t 0.2887163460254669\n",
      "Epoch:\t 80 \t\t\tValid Accuracy\t 0.996875\n",
      "Epoch:\t 81 \tStep:\t 0 \tLoss:\t 0.26714012026786804\n",
      "Epoch:\t 81 \t\t\tValid Accuracy\t 0.9971875\n",
      "Epoch:\t 82 \tStep:\t 0 \tLoss:\t 0.250465989112854\n",
      "Epoch:\t 82 \t\t\tValid Accuracy\t 0.99796873\n",
      "Epoch:\t 83 \tStep:\t 0 \tLoss:\t 0.23572029173374176\n",
      "Epoch:\t 83 \t\t\tValid Accuracy\t 0.9982031\n",
      "Epoch:\t 84 \tStep:\t 0 \tLoss:\t 0.22763484716415405\n",
      "Epoch:\t 84 \t\t\tValid Accuracy\t 0.9984375\n",
      "Epoch:\t 85 \tStep:\t 0 \tLoss:\t 0.2141188085079193\n",
      "Epoch:\t 85 \t\t\tValid Accuracy\t 0.9982031\n",
      "Epoch:\t 86 \tStep:\t 0 \tLoss:\t 0.19772440195083618\n",
      "Epoch:\t 86 \t\t\tValid Accuracy\t 0.9985937\n",
      "Epoch:\t 87 \tStep:\t 0 \tLoss:\t 0.19153103232383728\n",
      "Epoch:\t 87 \t\t\tValid Accuracy\t 0.9985156\n",
      "Epoch:\t 88 \tStep:\t 0 \tLoss:\t 0.18131938576698303\n",
      "Epoch:\t 88 \t\t\tValid Accuracy\t 0.99882805\n",
      "Epoch:\t 89 \tStep:\t 0 \tLoss:\t 0.17507293820381165\n",
      "Epoch:\t 89 \t\t\tValid Accuracy\t 0.9988281\n",
      "Epoch:\t 90 \tStep:\t 0 \tLoss:\t 0.16480888426303864\n",
      "Epoch:\t 90 \t\t\tValid Accuracy\t 0.9992187\n",
      "Epoch:\t 91 \tStep:\t 0 \tLoss:\t 0.1576976180076599\n",
      "Epoch:\t 91 \t\t\tValid Accuracy\t 0.9994531\n",
      "Epoch:\t 92 \tStep:\t 0 \tLoss:\t 0.14615577459335327\n",
      "Epoch:\t 92 \t\t\tValid Accuracy\t 0.99960935\n",
      "Epoch:\t 93 \tStep:\t 0 \tLoss:\t 0.13900771737098694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 93 \t\t\tValid Accuracy\t 0.99953127\n",
      "Epoch:\t 94 \tStep:\t 0 \tLoss:\t 0.13630490005016327\n",
      "Epoch:\t 94 \t\t\tValid Accuracy\t 0.9996875\n",
      "Epoch:\t 95 \tStep:\t 0 \tLoss:\t 0.13207511603832245\n",
      "Epoch:\t 95 \t\t\tValid Accuracy\t 0.9992969\n",
      "Epoch:\t 96 \tStep:\t 0 \tLoss:\t 0.12662336230278015\n",
      "Epoch:\t 96 \t\t\tValid Accuracy\t 0.99953127\n",
      "Epoch:\t 97 \tStep:\t 0 \tLoss:\t 0.11802639812231064\n",
      "Epoch:\t 97 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 98 \tStep:\t 0 \tLoss:\t 0.11407341808080673\n",
      "Epoch:\t 98 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 99 \tStep:\t 0 \tLoss:\t 0.10969527065753937\n",
      "Epoch:\t 99 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 100 \tStep:\t 0 \tLoss:\t 0.10536570847034454\n",
      "Epoch:\t 100 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 101 \tStep:\t 0 \tLoss:\t 0.10417982935905457\n",
      "Epoch:\t 101 \t\t\tValid Accuracy\t 0.9996875\n",
      "Epoch:\t 102 \tStep:\t 0 \tLoss:\t 0.09748704731464386\n",
      "Epoch:\t 102 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 103 \tStep:\t 0 \tLoss:\t 0.09466937929391861\n",
      "Epoch:\t 103 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 104 \tStep:\t 0 \tLoss:\t 0.0924793928861618\n",
      "Epoch:\t 104 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 105 \tStep:\t 0 \tLoss:\t 0.08762393146753311\n",
      "Epoch:\t 105 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 106 \tStep:\t 0 \tLoss:\t 0.08354819566011429\n",
      "Epoch:\t 106 \t\t\tValid Accuracy\t 0.99976563\n",
      "Epoch:\t 107 \tStep:\t 0 \tLoss:\t 0.08247868716716766\n",
      "Epoch:\t 107 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 108 \tStep:\t 0 \tLoss:\t 0.07971376180648804\n",
      "Epoch:\t 108 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 109 \tStep:\t 0 \tLoss:\t 0.07784673571586609\n",
      "Epoch:\t 109 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 110 \tStep:\t 0 \tLoss:\t 0.07483170181512833\n",
      "Epoch:\t 110 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 111 \tStep:\t 0 \tLoss:\t 0.07240922003984451\n",
      "Epoch:\t 111 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 112 \tStep:\t 0 \tLoss:\t 0.0695895105600357\n",
      "Epoch:\t 112 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 113 \tStep:\t 0 \tLoss:\t 0.06876163929700851\n",
      "Epoch:\t 113 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 114 \tStep:\t 0 \tLoss:\t 0.06241495907306671\n",
      "Epoch:\t 114 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 115 \tStep:\t 0 \tLoss:\t 0.06462624669075012\n",
      "Epoch:\t 115 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 116 \tStep:\t 0 \tLoss:\t 0.06134767457842827\n",
      "Epoch:\t 116 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 117 \tStep:\t 0 \tLoss:\t 0.06033468618988991\n",
      "Epoch:\t 117 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 118 \tStep:\t 0 \tLoss:\t 0.05838519707322121\n",
      "Epoch:\t 118 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 119 \tStep:\t 0 \tLoss:\t 0.057246483862400055\n",
      "Epoch:\t 119 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 120 \tStep:\t 0 \tLoss:\t 0.053945086896419525\n",
      "Epoch:\t 120 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 121 \tStep:\t 0 \tLoss:\t 0.05418574437499046\n",
      "Epoch:\t 121 \t\t\tValid Accuracy\t 0.9998437\n",
      "Epoch:\t 122 \tStep:\t 0 \tLoss:\t 0.051454197615385056\n",
      "Epoch:\t 122 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 123 \tStep:\t 0 \tLoss:\t 0.05056246370077133\n",
      "Epoch:\t 123 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 124 \tStep:\t 0 \tLoss:\t 0.048538632690906525\n",
      "Epoch:\t 124 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 125 \tStep:\t 0 \tLoss:\t 0.04902547225356102\n",
      "Epoch:\t 125 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 126 \tStep:\t 0 \tLoss:\t 0.04700144752860069\n",
      "Epoch:\t 126 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 127 \tStep:\t 0 \tLoss:\t 0.04531986266374588\n",
      "Epoch:\t 127 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 128 \tStep:\t 0 \tLoss:\t 0.04320546239614487\n",
      "Epoch:\t 128 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 129 \tStep:\t 0 \tLoss:\t 0.04339613765478134\n",
      "Epoch:\t 129 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 130 \tStep:\t 0 \tLoss:\t 0.041811954230070114\n",
      "Epoch:\t 130 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 131 \tStep:\t 0 \tLoss:\t 0.04186950623989105\n",
      "Epoch:\t 131 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 132 \tStep:\t 0 \tLoss:\t 0.04096537083387375\n",
      "Epoch:\t 132 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 133 \tStep:\t 0 \tLoss:\t 0.03848947957158089\n",
      "Epoch:\t 133 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 134 \tStep:\t 0 \tLoss:\t 0.03726792335510254\n",
      "Epoch:\t 134 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 135 \tStep:\t 0 \tLoss:\t 0.03708570450544357\n",
      "Epoch:\t 135 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 136 \tStep:\t 0 \tLoss:\t 0.036106277257204056\n",
      "Epoch:\t 136 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 137 \tStep:\t 0 \tLoss:\t 0.03501863405108452\n",
      "Epoch:\t 137 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 138 \tStep:\t 0 \tLoss:\t 0.03557460755109787\n",
      "Epoch:\t 138 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 139 \tStep:\t 0 \tLoss:\t 0.03353807330131531\n",
      "Epoch:\t 139 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 140 \tStep:\t 0 \tLoss:\t 0.03260305896401405\n",
      "Epoch:\t 140 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 141 \tStep:\t 0 \tLoss:\t 0.03180716186761856\n",
      "Epoch:\t 141 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 142 \tStep:\t 0 \tLoss:\t 0.031369343400001526\n",
      "Epoch:\t 142 \t\t\tValid Accuracy\t 0.99992186\n",
      "Epoch:\t 143 \tStep:\t 0 \tLoss:\t 0.031365424394607544\n",
      "Epoch:\t 143 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 144 \tStep:\t 0 \tLoss:\t 0.030846748501062393\n",
      "Epoch:\t 144 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 145 \tStep:\t 0 \tLoss:\t 0.03016342967748642\n",
      "Epoch:\t 145 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 146 \tStep:\t 0 \tLoss:\t 0.028978699818253517\n",
      "Epoch:\t 146 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 147 \tStep:\t 0 \tLoss:\t 0.02845821902155876\n",
      "Epoch:\t 147 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 148 \tStep:\t 0 \tLoss:\t 0.027263829484581947\n",
      "Epoch:\t 148 \t\t\tValid Accuracy\t 1.0\n",
      "Epoch:\t 149 \tStep:\t 0 \tLoss:\t 0.027331087738275528\n",
      "Epoch:\t 149 \t\t\tValid Accuracy\t 1.0\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dl, valid_dl, loss_fn, optimizer, num_epochs=150, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works. \n",
    "\n",
    "We've basically made a very expensive `reversed()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
